
docker run --gpus all --name "nguyenpdg_paddleocr_svtr" -v /HDD4T/nguyenpdg/:/code -v /media/nguyenpdg/:/data --shm-size=64G --network=host --ulimit memlock=-1 -it paddlepaddle/paddle:2.3.2-gpu-cuda11.2-cudnn8 /bin/bash

-c "rm /etc/apt/sources.list.d/cuda.list \
    && rm /etc/apt/sources.list.d/nvidia-ml.list \
    && apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub \
    && apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub \ 
    \
    && apt-get update && apt-get install -y libgl1 libglib2.0-0 git nano wget \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* 
    \
    && cd /code/ \
    && git clone -b nguyenpdg https://github.com/giacnguyenbmt/PaddleOCR.git \
    && cd PaddleOCR \
    && pip install -r requirements.txt \
    \
    && python svtr_trainning/prepare_data.py \
    \
    && mkdir models \
    && cd models \
    && wget https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/rec_svtr_large_none_ctc_ch_train.tar \
    && rec_svtr_large_none_ctc_ch_train.tar \
    && cd .. \
    \
    && python tools/train.py -c configs/rec/rec_svtrnet_large_lpr.yml -o \
    Global.pretrained_model=models/rec_svtr_large_none_ctc_ch_train/best_accuracy.pdparams \
    Global.eval_batch_step="[0, 4478]" \
    Train.dataset.data_dir="/" \
    Train.dataset.label_file_list=[/data/lpr_vht_hnc_v4/train.txt] \
    Eval.dataset.data_dir="/" \
    Eval.dataset.label_file_list=[/data/lpr_vht_hnc_v4/val.txt] "
